# Deep Learn Fund - Experimenting with ResNet-18 on CIFAR-10 (Grid Search)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision.models import resnet18
from torch.utils.data import DataLoader, random_split
import time

# Confirm GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
batch_size = 128
weight_decay = 1e-4
validation_split = 0.1  # 10% validation

# Data augmentation and normalization
transform_augmented = transforms.Compose([
    transforms.Resize(224),
    transforms.RandomCrop(224, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

# Load CIFAR-10 with train, validation, and test splits
def load_data(transform_train, transform_test):
    # Load and split CIFAR-10 with given transforms
    full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    train_size = int((1 - validation_split) * len(full_trainset))
    val_size = len(full_trainset) - train_size
    trainset, valset = random_split(full_trainset, [train_size, val_size])

    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

    return trainloader, valloader, testloader

# Initialize and customize ResNet-18
def create_model():
    # Load ResNet-18 and adapt final layer for CIFAR-10 classes
    model = resnet18(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, 10)  # Adjust output layer for 10 classes
    return model.to(device)

# Model training function
def train_model(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs):
    best_val_accuracy = 0
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in trainloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        scheduler.step()

        # Evaluate on validation set
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for inputs, labels in valloader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        val_accuracy = 100 * correct / total
        print(f"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(trainloader):.4f}, Val Acc: {val_accuracy:.2f}%")

        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy

    return best_val_accuracy

# Run training with specific hyperparameters
def run_experiment(num_epochs, learning_rate):
    # Run training experiment with the given learning rate and epoch count
    print(f"\nRunning experiment - Epochs: {num_epochs}, LR: {learning_rate}")

    trainloader, valloader, testloader = load_data(transform_augmented, transform_augmented)
    model = create_model()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)

    start_time = time.time()
    best_val_accuracy = train_model(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs)
    end_time = time.time()

    # Final test evaluation
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    test_accuracy = 100 * correct / total
    print(f"Best Val Accuracy: {best_val_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%")
    print(f"Total Training Time: {end_time - start_time:.2f}s")

    return best_val_accuracy, test_accuracy

# Grid search on epochs and learning rates
results = {}
for num_epochs in [20, 40]:
    for learning_rate in [0.01, 0.001]:
        config_name = f"Epochs_{num_epochs}_LR_{learning_rate}"
        results[config_name] = run_experiment(num_epochs, learning_rate)

# Summarize results
print("\nResults Summary:")
for config, (val_accuracy, test_accuracy) in results.items():
    print(f"{config}: Val Acc: {val_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%")

# Report best config based on validation accuracy
best_config = max(results, key=lambda k: results[k][0])
print(f"\nBest Config: {best_config}")
print(f"Best Validation Accuracy: {results[best_config][0]:.2f}%")
print(f"Corresponding Test Accuracy: {results[best_config][1]:.2f}%")

